In this section we introduce the notion of stochastic localization schemes. 
To gain an intuition for these objects, we also present several examples which 
is be studied further in subsequent sections. \todo{More intro}

We work in general Borel spaces \((\mathcal{X}, \Sigma)\) for this section while restricting our 
focus to either the Euclidean space \(\mathbb{R}^n\) or the Boolean hypercube \(\{-1, 1\}^n\) 
in subsequent sections. We take \((\Omega, \mathscr{F}, \mathbb{P})\) our underlying probability space 
and we introduce the notation \(\mathcal{M}(\mathcal{X})\) for the space of probability measures on 
\(\mathcal{X}\).

\begin{definition}[Prelocalization process]
  Given \(\mu \in \mathcal{M}(\mathcal{X})\), a measure-valued stochastic process 
  \((\mu_t)_{t \ge 0}\) is said to be a prelocalization of \(\mu\) if 
  \begin{enumerate}[label=(L\arabic*), start=0]
    \item \label{L0} \(\mu_0 = \mu\).
    \item \label{L1} For all \(t \ge 0\), \(\mu_t\) is a probability measure almost everywhere, i.e. 
      \(\mathbb{P}(\mu_t(\mathcal{X}) = 1) = 1\).
    \item \label{L2} For all \(A \in \Sigma\), \((\mu_t(A))_{t \ge 0}\) is a martingale with respect 
      to the natural filtration of \((\mu_t)\).
  \end{enumerate}
  Where \(\mathcal{M}(\mathcal{X})\) is equipped with the \(\sigma\)-algebra generated by maps of the form 
  \[\pi_A : \mathcal{M}(\mathcal{X}) \mapsto \mathbb{R}_{\ge 0} \cup \{\infty\} : \mu \mapsto \mu(A)\] 
  for all \(A \in \Sigma\). Equivalently, this is the Borel \(\sigma\)-algebra on \(\mathcal{M}(\mathcal{X})\) 
  using the topology induced by the total variation norm.
\end{definition}

\begin{definition}[Stochastic localization process, \cite{Chen_2022}]
  Given \(\mu \in \mathcal{M}(\mathcal{X})\), a measure-valued stochastic process 
  \((\mu_t)_{t \ge 0}\) is said to be a stochastic localization of \(\mu\) if in addition to being a 
  prelocalization of \(\mu\), \((\mu_t)_{t \ge 0}\) also satisfies
  \begin{enumerate}[label=(L\arabic*), start=3]
    \item \label{L3} For all \(A \in \Sigma\), \(\mu_t(A)\) converges almost everywhere to \(0\) 
      or \(1\) as \(t \to \infty\).
  \end{enumerate}
\end{definition}

\begin{definition}[Stochastic localization scheme, \cite{Chen_2022}]
  Denoting \(\mathcal{L}(\mu)\) the set of all stochastic localization processes of the measure
  \(\mu\), a stochastic localization scheme is a map 
  \[\Phi : \mathcal{M}(\mathcal{X}) \to \coprod_{\mu \in \mathcal{M}(\mathcal{X})} \mathcal{L}(\mu)\] 
  such that \(\Phi(\mu) \in \mathcal{L}(\mu)\) for all \(\mu \in \mathcal{M}(\mathcal{X})\).
\end{definition}

We say a stochastic localization is discrete if \(t\) takes value in \(\mathbb{N}\) and continuous 
if \(t\) takes value in \(\mathbb{R}_{\ge 0}\). For shorthand, we denote \((\mu_k)_k\) for a
discrete stochastic localization of \(\mu\).

\begin{proposition}\label{prop:stoch_loc}
  Straightaway, by the martingale property, if \((\mu_t)_{t \ge 0}\) is a stochastic localization of \(\mu\), 
  then 
  \begin{itemize}
    \item \(\mathbb{E}[\mu_t] = \mu\) for all \(t \ge 0\).
    \item taking \(X \sim \mu\) such that \(\mu_t \to \delta_X\) almost everywhere as \(t \to \infty\) 
      (here weak and total variational convergence are equivalent and so \(\to\) can mean either).
  \end{itemize}
\end{proposition}
\begin{proof}
  The first statement is immediate as for all \(A \in \Sigma\), 
  \[\mathbb{E}[\mu_t](A) \triangleq \mathbb{E}[\mu_t(A)] = \mathbb{E}[\mu_0(A)] = \mu(A).\]
  To prove the second statement, let us first parse what the claim is. Fixing a realization \(\omega\) of \(\mu_t\), 
  we have by \ref{L3} that \(\mu_t\) converges to some Dirac measure based at some \(x_\omega \in \mathcal{X}\). Thus, 
  defining the random variable \(X : \omega \mapsto x_\omega\), it suffices to show \(X \sim \mu\). 
  Indeed, by taking \(\phi : \mathcal{X} \to \mathbb{R}\) to be any bounded and continuous function, by the 
  definition of \(X\)
  \[\int \phi(x) \mu_t(\dd x) \xrightarrow{\text{a.e.}} \int \phi(x) \delta_{X}(\dd x) = \phi(X) \text{ as } t \to \infty.\]
  Thus, taking expectation on both sides, we have 
  \[\mathbb{E}[\phi(X)] = \mathbb{E}\left[\int \phi \dd \mu_t\right] = 
    \int \phi \dd \mathbb{E}[\mu_t] = \int \phi \dd \mu\]
  implying \(X \sim \mu\) as required.
\end{proof}

An example of a stochastic localization scheme is the coordinate by coordinate localization scheme 
on \(\mathcal{X} = \{-1, 1\}^n\). This scheme relates to the Glauber dynamics for which the stochastic 
localization scheme provides a mixing bound. We shall examine the property in section~\ref{sec:Glauber_loc}, 
though we will construct the scheme now. 

Given a probability measure \(\mu\) on \(\{-1, 1\}^n\), we introduce the random variable \(X \sim \mu\), and 
\(Y\) a uniform random variable over all permutations of \([n] = \{1, \cdots, n\}\) independent of \(X\). 
Then, the coordinate by coordinate stochastic localization of \(\mu\) is the process \((\mu_k)_{k}\)
such that for all \(x \in \{-1, 1\}^n\),
\[\mu_k(x) = \mathbb{P}(X = x \mid X_{Y_1}, \cdots, X_{Y_{n \wedge k}}).\]
Namely, \(\mu_k\) is the law of \(X\) conditioned on \(X_{Y_1}, \cdots, X_{Y_i}\).

\((\mu_k)_{k}\) is indeed a stochastic localization of \(\mu\). It is clear that \ref{L0} and \ref{L1} are 
satisfied. By construction of \((\mu_k)_k\), denoting 
\(\mathscr{F}_k := \sigma(X_{Y_1}, \cdots, X_{Y_{n \wedge k}})\), we have by the tower property
\[\mathbb{E}[\mu_{k + 1}(x) \mid \mathscr{F}_k] 
  = \mathbb{E}[\mathbb{E}[\mathbb{P}(X = x \mid X) \mid \mathscr{F}_{k + 1}] \mid \mathscr{F}_k]
  = \mathbb{E}[\mathbb{P}(X = x \mid X) \mid \mathscr{F}_k] = \mu_k(x)\]
implying \((\mu_k(x))\) a martingale as required for \ref{L2}. Finally, it is clear that
\[\lim_{k \to \infty} \mu_k(x) = \mu_n(x) = \mathbb{P}(X = x \mid X) = \mathbf{1}_{\{X = x\}} \in \{0, 1\}\]
implying \ref{L3}.

An analogous construction of the coordinate by coordinate stochastic localization scheme in \(\mathbb{R}^n\) 
is the random subspace localization. Similar to before, for a probability measure \(\mu\) on \(\mathbb{R}^n\),
we introduce the random variable \(X \sim \mu\) and \(Y\) a uniform random variable on \(O(n)\) 
(so the column vectors \(\{Y_1, \cdots, Y_n\}\) form an orthonormal basis of \(\mathbb{R}^n\)) 
independent of \(X\). Then, we define the random subspace stochastic localization of \(\mu\) as \((\mu_k)_k\) 
where \(\mu_k\) is the law of \(X\) conditioned on \(\langle X, Y_1\rangle, \cdots, \langle X, Y_{n \wedge k}\rangle\).

\subsection{Linear-tilt localization schemes}

An important class of stochastic localization schemes are the linear-tilt schemes. Introduced by Eldan 
in \cite{Eldan_2013}, linear-tilt schemes has been vital in the recent progress regarding the KLS 
conjecture. More recently, a discrete version of the linear-tilt scheme was introduced in \cite{Chen_2022}
and is used to provide a mixing bound for Glauber dynamics. We will in this section introduce these family 
of localizations and consider two specific examples of such linear-tilt schemes which are 
useful for our analysis later.

Informally, given a probability measure \(\mu\) on \(\mathcal{X} \subseteq \mathbb{R}^n\), the linear-tilt scheme
of \(\mu\) is constructed recursively in which at each step, we pick a random direction and multiply 
the density at this time with a linear function along this direction (i.e. a tilt along a random 
direction). 

Let \(\mu\) be a probability measure on \(\mathcal{X} \subseteq \mathbb{R}^n\), we introduce the following definition.
\begin{definition}[Barycenter]
  The barycenter of \(\mu\) with respect to the function \(F : \mathbb{R}^n \to \mathbb{R}\) is
  \[\bar{\mu}(F) := \int_{\mathcal{X}} x F(x) \mu(\dd x).\]
  In the case that \(F = \text{id}\), we simply write \(\bar{\mu} = \bar{\mu}(F) = \mathbb{E}_{X \sim \mu}[X]\).
\end{definition}

\begin{definition}[Linear-tilt localization]
  A measure-valued stochastic process \((\mu_t)_{t \ge 0}\) is said to be a linear-tilt localization of
  the probability measure \(\mu\) if 
  \begin{enumerate}
    \item \(\mu_t \ll \mu\) for each \(t \ge 0\), and 
    \item denoting \(F_t := \dd \mu_t / \dd \mu\), we have \(F_0 = 1\) and 
      \begin{equation}\label{eq:linear-tilt}
        \dd F_t(x) = \langle x - \bar{\mu}(F_t), \dd Z_t \rangle F_t(x)
      \end{equation}
      for some stochastic process \((Z_t)_{t \ge 0}\) such that \(\mathbb{E}[\dd Z_t \mid \mu_t] = 0\) 
      for all \(t \ge 0\). 
  \end{enumerate} 
\end{definition}

It is clear that \((\mu_t(A))_t\) is a martingale for all \(A \in \Sigma\) by observing that 
equation~\eqref{eq:linear-tilt} has no drift term. Furthermore, since \(\mu_t(\mathcal{X}) = \int F_t \dd \mu\) is differentiable by 
construction, \((\mu_t(\mathcal{X}))\) has zero quadratic variation and thus is constant in \(t\). 
With this in mind, as \(\mu_0 = \mu\) is a probability measure, it follows:

\begin{proposition}
  If \((\mu_t)_t\) is a linear-tilt localization of \(\mu\), then \(\mu_t\) is a probability measure for each \(t\).
\end{proposition}

\begin{corollary}
  A linear-tilt localization \((\mu_t)_t\) of \(\mu\) is a prelocalization of \(\mu\).
\end{corollary}

We remark that in general, a linear-tilt localization is not necessarily a stochastic localization as \ref{L3} 
might not be satisfied. It is possible to impose sufficient conditions on \((Z_t)\) for which \ref{L3} holds,
e.g. by requiring \(\|\text{Cov}(Z_t)\|_{\text{op}}\) to decrease sufficiently fast. However, for generality, 
we will not restrict ourselves to one of these conditions. Instead, we will consider \ref{L3} case by case 
in the following examples of linear-tilt schemes. 

\subsubsection{Linear-tilt localization driven by a Wiener process}\label{sec:construct}

A natural choice of \((Z_t)_{t \ge 0}\) is the standard Wiener process on \(\mathbb{R}^n\).
Denoting \((W_t)_{t \ge 0}\) a standard Wiener process on \(\mathbb{R}^n\), we define the random functions 
\((F_t)_{t \ge 0}\) to be the solution of the following infinite system of SDEs 
(existence and uniqueness is established by theorem 5.2 in \cite{Øksendal_2003}): 
\begin{equation}\label{eq:stoch_loc}
  F_0 = 1, \dd F_t(x) = \langle x - \bar{\mu}(F_t), \dd W_t \rangle F_t(x),
\end{equation}
for all \(x \in \mathbb{R}^n\). We shall from this point forward denote the random variables \(a_t := \bar{\mu}(F_t)\).

By applying Itô's formula, we make the following useful observation: for all \(x \in \mathbb{R}^n\),
\begin{equation}
  \dd \log F_t(x) = \frac{\dd F_t(x)}{F_t(x)} - \frac{\dd\hspace{0pt} [F(x)]_t}{2F_t(x)^2} 
    = \langle x - a_t, \dd W_t \rangle - \frac{1}{2}\|x - a_t\|^2 \dd t
\end{equation}
where the second equality follows by the construction of \(F\). Hence, as \(\log F_0(x) = 0\), we 
observe
\begin{align*}
  \log F_t(x) & = \int_0^t \langle x - a_s, \dd W_s \rangle - \frac{1}{2}\int_0^t \|x - a_s\|^2 \dd s\\
    & = \left(\langle x, W_t \rangle - \int_0^t \langle a_s, \dd W_s \rangle\right)
      - \left(\frac{t}{2}\|x\|^2 + \frac{1}{2}\int_0^t\|a_s\|^2 \dd s - \int_0^t \langle x, a_s \rangle \dd s\right)\\
    & = - \left(\int_0^t \langle a_s, \dd W_s \rangle + \frac{1}{2}\|a_s\|^2 \dd s\right) + 
      \langle x, a_t + W_t \rangle - \frac{t}{2}\|x\|^2.
\end{align*}
Thus, taking \(\dd z_t := \langle a_t, \dd W_t\rangle + \frac{1}{2} \|a_t\|^2 \dd t\) and 
\(v_t := a_t + W_t\), we observe \(F_t(x)\) is of the form
\begin{equation}\label{eq:stoch_loc_alt}
  F_t(x) = e^{z_t + \langle x, v_t \rangle - \frac{t}{2}\|x\|^2},
\end{equation}
for given Itô processes \((z_t), (v_t)\).

With this formulation of \(F_t(x)\) in mind, it follows \(F_t\) is non-negative, and so, 
we may define \((\mu_t)_t\) to be the process such that \(\dd \mu_t = F_t \dd \mu\). It is clear that 
\((\mu_t)_t\) is a linear-tilt localization of \(\mu\) and so, is a prelocalization of \(\mu\).
The remainder of this section is devoted to showing \((\mu_t)_t\) is furthermore a stochastic localization 
of \(\mu\) if \(\mu\) is log-concave (namely we will show \ref{L3} for this special case), and prove 
some basic properties about this process useful for our analysis later.

\begin{definition}[Log-concave measure]
  A measure \(\mu\) on \(\mathbb{R}^n\) is said to log-concave if it is of the form 
  \(\dd \mu = \exp(-H)\dd\text{Leb}^n\) for some convex function \(H : \mathbb{R}^n \to \mathbb{R} \cup \{\infty\}\)
\end{definition}

To show \((\mu_t)\) satisfies \ref{L3} if \(\mu\) is log-concave, we study the limiting behavior of 
\((\mu_t)\) as \(t \to \infty\) by considering their covariances:
\begin{equation}
  A_t := \text{Cov}[\mu_t] = \int (x - a_t) \otimes (x - a_t) \mu_t(\dd x),
\end{equation}
where \(\otimes\) denotes the Kronecker product. In particular, we will show \((A_t)_{ij} \to 0\) for all
 \(i, j \in \{1, \cdots, n\}\) as \(t \to \infty\) allowing us to conclude \((\mu_t)\) converges weakly 
 to some Dirac measure. Indeed, this is a direct consequence of the following lemma.

\begin{lemma}[Brascamp-Lieb inequality, \cite{Brascamp_1976}]\label{lem:brascamp-lieb}
  Given \(V : \mathbb{R}^n \to \mathbb{R}\) convex and \(K > 0\), if \(\nu\) is an isotropic probability 
  measure on \(\mathbb{R}^n\) of the form 
  \[\dd \nu = Ze^{-V(x) - \frac{1}{2K}\|x\|^2}\dd \text{Leb}^n\]
  with \(Z\) being the normalization constant, then \(\nu\) satisfy the Poincaré inequality, i.e. 
  for all differentiable \(\phi\),
  \[K\text{Var}_\nu[\phi] \le \int \|\nabla\phi\|^2 \dd\nu.\]
\end{lemma}

With this lemma in mind, by taking \(\nu = \mu_t\) using 
equation~\eqref{eq:stoch_loc_alt} and defining
\(\pi_i(x) := x_i\), we have by the Cauchy-Schwarz inequality
\[(A_t)_{ij} \le \sqrt{\text{Var}_{\mu_t}[\pi_i]}\sqrt{\text{Var}_{\mu_t}[\pi_j]} 
  \le \max_{k = 1, \cdots, n} \frac{1}{t}\int \|\nabla \pi_k\|^2 \dd \mu_t\]
Again, using equation~\eqref{eq:stoch_loc_alt}, we note that any realizations of \((F_t(x))\) is eventually 
decreasing in \(t\) for all \(x \neq 0\), implying 
\[\sup_{t > 0} \max_{k = 1, \cdots, n} \int \|\nabla \pi_k\|^2 \dd \mu_t = 
\sup_{t > 0} \max_{k = 1, \cdots, n} \int x_k^2 \dd \mu_t < \infty.\] 
Thus, by taking \(t \to \infty\) we have \((A_t)_{ij} \to 0\) for all \(i, j \in \{1, \cdots, n\}\) as claimed 
and we have \((\mu_t)\) satisfying \ref{L3} and hence, is a stochastic localization of \(\mu\).

\begin{corollary}
  \((\mu_t)\) converges set-wise to some Dirac measure almost everywhere. We denote this 
  limiting (random) Dirac measure by \(\delta_{a_\infty}\) where \(a_\infty\) is some 
  \(\mathbb{R}^n\)-valued random variable.
\end{corollary}

As a result of proposition~\ref{prop:stoch_loc}, we also have the following corollaries.

\begin{corollary}\label{cor:lim_dis}
  The massive point \(a_\infty\) of the limiting Dirac measure is the limit of \(a_t\) as 
  \(t \to \infty\) and has law \(\mu\).
\end{corollary}
% \begin{proof}
%   Since convergence implies relatively compact, applying the Dunford-Pettis theorem it follows that 
%   any realizations of \((F_t)\) is uniformly integrable. Thus, the result follows by the Vitali 
%   convergence theorem.
% \end{proof}

\begin{corollary}\label{cor:lim_mart}
  Taking \(\phi\) to be any continuous function, we define \(M_t = \int \phi \dd\mu_t\). Then,
  \((M_t)_{t \ge 0}\) is a martingale and
  \begin{equation}\label{eq:lim_mart}
    M_t \xrightarrow{\text{a.e.}} \phi(a_\infty) \sim \phi_* \mu
  \end{equation}
  where \(\phi_*\mu\) denotes the push-forward measure of \(\mu\) along \(\phi\).
\end{corollary}

\subsubsection{Discrete time linear-tilt localization}\label{sec:discrete_tilt}

We may construct an analogous version of the linear-tilt localization for discrete time. By utilizing 
the little-\(o\) notation, equation~\eqref{eq:linear-tilt} can be rewritten as 
\[\frac{\dd \mu_{t + h}}{\dd \mu}(x) = 
  \frac{\dd \mu_t}{\dd \mu}(x) + \langle x - \bar{\mu}_t, h\dd Z_t\rangle \frac{\dd \mu_t}{\dd \mu}(x) 
  + o(h).\]
Hence, an discrete analog of the linear tilt localization is defined as the following.

\begin{definition}[Discrete time linear-tilt localization]
  Given a measure \(\mu \in \mathcal{M}(\mathcal{X})\), the discrete time linear-tilt localization 
  is the sequence of random measures \((\mu_k)_k\) defined by \(\mu_0 = \mu\) and 
  \begin{equation}\label{eq:discrete_tilt}
    \dd \mu_{k + 1} = (1 + \langle x - \bar{\mu}_k, Z_k \rangle)\dd \mu_k
  \end{equation} 
  for some sequence of random variables such that \(\mathbb{E}[Z_k \mid \mu_k] = 0\) for all 
  \(k \in \mathbb{N}\).
\end{definition}

The coordinate by coordinate localization can be formulated as a discrete time linear-tilt localization.
Given \(\mu\) a probability measure on \(\{-1, 1\}^n\), we recall that the coordinate by coordinate 
localization is defined by ``pinning'' an additional random coordinate after each time step. To phrase 
this as a linear-tilt localization, we take the random variables \(Z_k\) to be
\begin{equation}\label{eq:def_Z}
  Z_k := e_{Y_k} \cdot
    \begin{cases}
      \frac{1}{1 + (\bar{\mu}_k)_{Y_k}} & \text{with probability } \frac{1 + (\bar{\mu}_k)_{Y_k}}{2} \\
      \frac{-1}{1 - (\bar{\mu}_k)_{Y_k}} & \text{with probability } \frac{1 - (\bar{\mu}_k)_{Y_k}}{2}
    \end{cases}
\end{equation}
where \(e_1, \cdots, e_n\) are the standard basis of \(\mathbb{R}^n\) and again \(Y\) is a uniform 
random variable over all permutations of \([n]\). Thus, the linear-tilt localization \((\mu_k)\) given by this 
choice of \((Z_k)\) is defined by
\[\mu_{k + 1}(\sigma) = (1 + \|Z_k\|(\sigma_{Y_k} - (\overline{\mu}_k)_{Y_k}))\mu_k(\sigma)\]
for all \(k < n\). Similar to before, we terminate the process at time \(n\) and so we extend the process 
to all times by taking \(\mu_k = \mu_{n \wedge k}\).

Let us parse this definition to see why this is equivalent to the coordinate by coordinate localization. 
Taking \(k < n\), we have at the \(k + 1\)-th step, \(Y_{k + 1}\) chooses a random axis
which had not been chosen before. Then, \(Z_k\) is chosen such that for each configuration \(\sigma\), 
the probability of \(\sigma_{Y_k}\) being \(\pm 1\) is proportional the mass of \(\mu_k\) on \(\pm e_{Y_k}\). 
This is precisely the steps needed to construct the coordinate by coordinate localization as conditioning 
on an additional axis in this case is simply a projection on to said axis. 