In this section, we will take a look at an application of the stochastic localization technic 
to prove a version of the log-Sobolev inequality for log-concave measures. The log-Sobolev inequality 
is a class of inequalities central to the concentration of measures and has applications to bounding 
Markov mixing times (c.f.\todo{TODO}). We will in particular\dots

\subsection{Entropy and log-Sobolev inequalities}

Heuristically, similar to that of the variance, the entropy of a random variable is a measure of its 
uncertainty or randomness. Formally, the entropy is defined as the following.

\begin{definition}[Entropy]
  Given \(\phi : \mathcal{X} \to \mathbb{R}_{\ge 0}\) and a measure \(\mu\), we define the entropy of \(\phi\) 
  with respect to \(\mu\) to be 
  \[\text{Ent}_\mu[\phi] := \mathbb{E}_\mu\left[\phi \log\left(\frac{1}{\mathbb{E}_\mu[\phi]} \phi\right)\right]
   = \int \phi \log \phi \dd \mu - \int \phi \dd \mu \log\left(\int \phi \dd \mu\right)\]
  with the convention that \(0\log 0 = 0\).
\end{definition}
The log-Sobolev inequality can be then formulated as the following.
\begin{definition}[Log-Sobolev inequality, \cite{Lee_2016}]
  For a given measure \(\mu\) on \(\mathbb{R}^n\), \(\mu\) is said to satisfy the log-Sobolev inequality with log-Sobolev 
  constant \(\rho_\mu\) if \(\rho_\mu\) is the largest \(\rho\) such that for all smooth 
  \(\phi : \mathbb{R}^n \to \mathbb{R}\) with \(\int \phi^2 \dd \mu = 1\), we have 
  \[\frac{\rho}{2} \text{Ent}_\mu[\phi^2] \le \mathbb{E}_\mu[\|\nabla \phi\|^2] = \int \|\nabla \phi\|^2 \dd \mu.\]
\end{definition}

The log-Sobolev inequality\todo{Motivation and Herbst.}
% https://faculty.math.illinois.edu/~psdey/math595fa19/lec14.pdf

We will in this section derive a bound for the log-Sobolev constant for all log-concave measures resulting in 
the following theorem. 

\begin{theorem}[\cite{Lee_2016}]
  For any isotropic log-concave measure \(\mu\) on \(\mathbb{R}^n\) with support on a ball of diameter \(D\), 
  \(\mu\) has log-Sobolev constant \(\rho_\mu \gtrsim D^{-1}\).
\end{theorem}

Before presenting Lee and Vempala's proof of above theorem, let us first remark the similarity of the 
log-Sobolev inequality with that of the Poincaré inequality. As a result, one might first attempt to analyze 
the log-Sobolev inequality using the same method as prescribed by section~\ref{sec:KLS_to_TS}. 

Given the smooth function \(\phi : \mathbb{R}^n \to \mathbb{R}\), let us define the martingale 
\(M_t := \int \phi^2 \dd \mu_t\) where \((\mu_t)\) is the linear-tilt localization described in section~\ref{sec:construct}. 
We observe
\begin{align*}
  \text{Ent}_\mu[\phi^2] & = \text{Ent}[M_\infty] 
    = \mathbb{E}[M_\infty \log M_\infty] - \mathbb{E}[M_\infty]\log(\mathbb{E}[M_\infty]) \\
  & = \mathbb{E}[\mathbb{E}[M_\infty \log M_\infty \mid \mu_t]] 
      - \mathbb{E}[\mathbb{E}[M_\infty \mid \mu_t]]\log(\mathbb{E}[\mathbb{E}[M_\infty \mid \mu_t]]) \\
  & = \mathbb{E}[\text{Ent}[M_\infty \mid \mu_t]] + \mathbb{E}[\mathbb{E}[M_\infty \mid \mu_t]\log(\mathbb{E}[M_\infty \mid \mu_t])]\\ 
  & \hspace{1cm} - \mathbb{E}[\mathbb{E}[M_\infty \mid \mu_t]]\log(\mathbb{E}[\mathbb{E}[M_\infty \mid \mu_t]])\\
  & = \mathbb{E}[\text{Ent}[M_\infty \mid \mu_t]] + \mathbb{E}[M_t \log M_t] - \mathbb{E}[M_t]\log(\mathbb{E}[M_t])\\
  & = \mathbb{E}[\text{Ent}[M_\infty \mid \mu_t]] + \text{Ent}[M_t]
\end{align*}
Moreover, defining the martingale \(N_t := \int \phi^2\log \phi^2 \dd \mu_t\), we observe
\begin{align*}
  \text{Ent}[M_\infty \mid \mu_t] 
  & = \mathbb{E}[M_\infty \log M_\infty \mid \mu_t] - \mathbb{E}[M_\infty \mid \mu_t]\log(\mathbb{E}[M_\infty \mid \mu_t]) \\
  & = \mathbb{E}[N_\infty \mid \mu_t] - M_t \log M_t = N_t - M_t \log M_t\\
  & = \mathbb{E}_{\mu_t}{\phi^2 \log \phi^2} - \mathbb{E}_{\mu_t}{\phi^2} \log \mathbb{E}_{\mu_t}{\phi^2} \\
  & = \text{Ent}_{\mu_t}[\phi^2].
\end{align*}
Thus, we can express the entropy of \(\phi^2\) with respect to \(\mu\) as 
\begin{equation}
  \text{Ent}_\mu[\phi^2] = \text{Ent}[M_t] + \mathbb{E}[\text{Ent}_{\mu_t}[\phi^2]].
\end{equation}
With this expression in mind, we may now attempt to bound each term individually while 
varying \(t\). Similar to the method in the case of the Poincaré inequality, in which we were able to bound the term 
\(\text{Var}_{\mu_t}[\phi]\) by using the Brascamp-Lieb inequality, we will bound \(\text{Ent}_{\mu_t}[\phi^2]\) 
by using an inequality by Bobkov and Ledoux.

\begin{lemma}[Bobkov-Ledoux, \cite{Bobkov_2000}]
  Let \(V : \mathbb{R}^n \to \mathbb{R}\) be a twice differentiable strictly convex function such that for all 
  \(v \in \mathbb{R}^n\), the map \(x \mapsto \langle V''(x) v, v\rangle\) is concave. Then, for all smooth functions
  \(\phi : \mathbb{R}^n \to \mathbb{R}\), we have 
  \[\text{Ent}_\nu[\phi^2] \le 3\mathbb{E}_\nu[\langle (V'')^{-1} \nabla\phi, \nabla \phi\rangle]\]
  where \(\dd \nu = e^{-V(x)} \dd \text{Leb}^n(x)\) and \(V''\) denotes the Hessian of \(V\).
\end{lemma}

Hence, by substituting \(\mu_t\) for \(\nu\) in the above lemma, where by equation~\eqref{eq:stoch_loc_alt}
we have that \(V'' = \frac{t}{2} \text{id}_n\), the map \(x \mapsto \langle V''(x) v, v\rangle\) is concave 
and hence, 
\[\text{Ent}_{\mu_t}[\phi^2] \le 6t^{-1}\mathbb{E}_{\mu_t}[\|\nabla\phi\|^2].\]