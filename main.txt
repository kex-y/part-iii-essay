WIP Title
Kexing Ying
December 30, 2022

Contents
1 Introduction
1.1 Structure of this essay . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2 Stochastic Localization Scheme

3
3
4

2.1 Linear-tilt localization schemes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6

2.1.1 Linear-tilt localization driven by Wiener process . . . . . . . . . . . . . . . .

7

2.1.2 Discrete time linear-tilt localization . . . . . . . . . . . . . . . . . . . . . . . .

9

3 Application: The KLS and Thin-Shell Conjecture

10

3.1 Concentration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.2 Example: concentration of the Gaussian . . . . . . . . . . . . . . . . . . . . . . . . . . 12
3.3 The KLS and thin-shell conjecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
3.3.1 Equivalent formulation of the KLS conjecture . . . . . . . . . . . . . . . . . . 13
3.4 Reduction of KLS to thin-shell . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
3.4.1 Differential of the quadratic variation . . . . . . . . . . . . . . . . . . . . . . . 15
3.4.2 Analysis of the covariance matrix . . . . . . . . . . . . . . . . . . . . . . . . . . 16
3.4.3 Stopping the process early . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
4 Application: Markov Mixing

21

4.1 Mixing bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
4.1.1 Ising model and Glauber dynamics . . . . . . . . . . . . . . . . . . . . . . . . . 22
4.2 Dynamics of stochastic localizations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
4.3 Glauber dynamics as an associated Markov process . . . . . . . . . . . . . . . . . . . 25

1

Introduction

1.1 Structure of this essay

3

2

Stochastic Localization Scheme

We will in this section introduce the notion of stochastic localization schemes. To gain an intuition for these objects, we will present several examples which will be studied further in subsequent sections.
We will work in general Borel spaces (X , Σ) for this section while for restrict our focus to either
the Euclidean space Rn or the Boolean hypercube {−1, 1}n in subsequent sections. We take
(Ω, F , P) our underlying probability space and we introduce the notation M (X ) for the space
of probability measures on X .
Deﬁnition 2.1 (Prelocalization process). Given µ ∈ M (X ), a measure-valued stochastic process
(µ t ) t≥0 is said to be a prelocalization of µ if
(L0) µ0 = µ.
(L1) For all t ≥ 0, µ t is a probability measure almost everywhere, i.e. P(µ t (X ) = 1) = 1.
(L2) For all A ∈ Σ, (µ t (A)) t≥0 is a martingale with respect to the natural ﬁltration of (µ t ).
Where M (X ) is equipped with the σ-algebra generated by maps of the form
πA : M (X ) 7→ R≥0 ∪ {∞} : µ 7→ µ(A)
for all A ∈ Σ. Equivalently, this is the Borel σ-algebra on M (X ) using the topology induced by
the total variation norm.
Deﬁnition 2.2 (Stochastic localization process, [CE22]). Given µ ∈ M (X ), a measure-valued
stochastic process (µ t ) t≥0 is said to be a stochastic localization of µ if in addition to being a
prelocalization of µ, (µ t ) t≥0 also satisﬁes
(L3) For all A ∈ Σ, µ t (A) converges almost everywhere to 0 or 1 as t → ∞.
Deﬁnition 2.3 (Stochastic localization scheme, [CE22]). Denoting L (µ) the set of all stochastic
localization processes of the measure µ, a stochastic localization scheme is a map
a
Φ : M (X ) →
L (µ)
µ∈M (X )

such that Φ(µ) ∈ L (µ) for all µ ∈ M (X ).
We say a stochastic localization is discrete if t takes value in N and continuous if t takes value
in R≥0 . For shorthand, we denote (µk )k for a discrete stochastic localization of µ.
Proposition 2.1. Straightaway, by the martingale property, if (µ t ) t≥0 is a stochastic localization
of µ, then
• E[µ t ] = µ for all t ≥ 0.
• taking X ∼ µ such that µ t → δX almost everywhere as t → ∞ (here weak and total
variational convergence are equivalent and so → can mean either).

4

Proof. The ﬁrst statement is immediate as for all A ∈ Σ,
E[µ t ](A) ¬ E[µ t (A)] = E[µ0 (A)] = µ(A).
To prove the second statement, let us ﬁrst parse what the claim is. Fixing a realization ω of µ t ,
we have by (L3) that µ t converges to some Dirac measure based at some x ω ∈ X . Thus, deﬁning
the random variable X : ω 7→ x ω , it sufﬁces to show X ∼ µ. Indeed, by taking ϕ : X → R to be
any bounded and continuous function, by the deﬁnition of X
Z
Z
a.e.

ϕ(x)µ t (dx) −→

ϕ(x)δX (dx) = ϕ(X ) as t → ∞.

Thus, taking expectation on both sides, we have
Z
 Z
E[ϕ(X )] = E

ϕdµ t =

Z
ϕdE[µ t ] =

ϕdµ

implying X ∼ µ as required.
An example of a stochastic localization scheme is the coordinate by coordinate localization
scheme on X = {−1, 1}n . This scheme relates to the Glauber dynamics for which the stochastic
localization scheme provides a mixing bound. We shall examine the property in section 4.3,
though we will construct the scheme now.
Given a probability measure µ on {−1, 1}n , we introduce the random variable X ∼ µ, and Y
a uniform random variable over all permutations of [n] = {1, · · · , n} independent of X . Then,
the coordinate by coordinate stochastic localization of µ is the process (µk )k such that for all
x ∈ {−1, 1}n ,
µk (x) = P(X = x | X Y1 , · · · , X Yn∧k ).
Namely, µk is the law of X conditioned on X Y1 , · · · , X Yi .
(µk )k is indeed a stochastic localization of µ. It is clear that (L0) and (L1) are satisﬁed. By
construction of (µk )k , denoting Fk := σ(X Y1 , · · · , X Yn∧k ), we have by the tower property
E[µk+1 (x) | Fk ] = E[E[P(X = x | X ) | Fk+1 ] | Fk ] = E[P(X = x | X ) | Fk ] = µk (x)
implying (µk (x)) a martingale as required for (L2). Finally, it is clear that
lim µk (x) = µn (x) = P(X = x | X ) = 1{X =x} ∈ {0, 1}

k→∞

implying (L3).
An analogous construction of the coordinate by coordinate stochastic localization scheme in Rn
is the random subspace localization. Similar to before, for a probability measure µ on Rn , we
introduce the random variable X ∼ µ and Y a uniform random variable on O(n) (so the column
vectors {Y1 , · · · , Yn } form an orthonormal basis of Rn ) independent of X . Then, we deﬁne the
random subspace stochastic localization of µ as (µk )k where µk is the law of X conditioned on
〈X , Y1 〉, · · · , 〈X , Yn∧k 〉.

5

2.1 Linear-tilt localization schemes
An important class of stochastic localization schemes are the linear-tilt schemes. Introduced by
Eldan in [Eld13], linear-tilt schemes has been vital in the recent progress regarding the KLS
conjecture. More recently, a discrete version of the linear-tilt scheme was introduced in [CE22]
and is used to provide a mixing bound for Glauber dynamics. We will in this section introduce
these family of localizations and consider two speciﬁc examples of such linear-tilt schemes which
are useful for our analysis later.
Informally, given a probability measure µ on X ⊆ Rn , the linear-tilt scheme of µ is constructed
recursively in which at each step, we pick a random direction and multiply the density at this
time with a linear function along this direction (i.e. a tilt along a random direction).
Let µ be a probability measure on X ⊆ Rn , we introduce the following deﬁnition.
Deﬁnition 2.4 (Barycenter). The barycenter of µ with respect to the function F : Rn → R is
Z
µ̄(F ) :=

x F (x)µ(dx).
X

In the case that F = id, we simply write µ̄ = µ̄(F ) = EX ∼µ [X ].
Deﬁnition 2.5 (Linear-tilt localization). A measure-valued stochastic process (µ t ) t≥0 is said to
be a linear-tilt localization of the probability measure µ if
1. µ t  µ for each t ≥ 0, and
2. denoting F t := dµ t /dµ, we have F0 = 1 and
dF t (x) = 〈x − µ̄(F t ), dZ t 〉F t (x)

(1)

for some stochastic process (Z t ) t≥0 such that E[dZ t | µ t ] = 0 for all t ≥ 0.
Proposition 2.2. If (µ t ) t is a linear-tilt localization of µ, then for all A ∈ Σ, dµ t (A) = 0 for all t.
Proof. Let A ∈ Σ, then we have
Z



dµ t (A) = dE[µ t (A) | µ t ] = E

dF t (x)µ(dx) µs
A

Z
=

E[〈x − µ̄(F t ), dZ t 〉F t (x) | µ t ]µ(dx)
ZA

=

〈x − µ̄(F t ), E[dZ t | µ t ]〉F t (x)µ(dx) = 0
A

as required.
Thus, as µ0 = µ is a probability measure, it follows µ t is a probability measure for each t.
Corollary 2.3. If (µ t ) t is a linear-tilt localization of µ then for all t, µ t is a probability measure.
Furthermore, as (F t (x)) t is a martingale by equation (1), it follows that (µ t (A)) t is a martingale
for all A ∈ Σ. Hence, we have:
6

Corollary 2.4. A linear-tilt localization (µ t ) t of µ is a prelocalization of µ.
We remark that in general, a linear-tilt localization is not necessarily a stochastic localization as
(L3) might not be satisﬁed. It is possible to impose sufﬁcient conditions on (Z t ) for which (L3)
holds, e.g. by requiring kCov(Z t )kop to decrease sufﬁciently fast. However, for generality, we
will not restrict ourselves to one of these conditions. Instead, we will consider (L3) case by case
in the following examples of linear-tilt schemes.
2.1.1

Linear-tilt localization driven by Wiener process

A natural choice of (Z t ) t≥0 is the standard Wiener process on Rn . Denoting (Wt ) t≥0 a standard
Wiener process on Rn , we deﬁne the random functions (F t ) t≥0 to be the solution of the following
inﬁnite system of SDEs (existence and uniqueness is established by theorem 5.2 in [Øks03]):
F0 = 1, dF t (x) = 〈x − µ̄(F t ), dWt 〉F t (x),

(2)

for all x ∈ Rn . We shall from this point forward denote the random variables a t := µ̄(F t ).
By applying Itô’s formula, we make the following useful observation: for all x ∈ Rn ,
d log F t (x) =

dF t (x) d[F (x)] t
1
−
= 〈x − a t , dWt 〉 − kx − a t k2 dt
2
F t (x)
2F t (x)
2

(3)

where the second equality follows by the construction of F . Hence, as log F0 (x) = 0, we observe
Z t
Z t
1
kx − as k2 ds
〈x − as , dWs 〉 −
log F t (x) =
2
0
0
 

Z t

Z t
Z t
t
1
2
2
〈as , dWs 〉 −
= 〈x, Wt 〉 −
〈x, as 〉ds
kas k ds −
kxk +
2
2 0
0
0
Z t

1
t
2
=−
〈as , dWs 〉 + kas k ds + 〈x, a t + Wt 〉 − kxk2 .
2
2
0
Thus, taking dz t := 〈a t , dWt 〉 + 12 ka t k2 dt and vt := a t + Wt , we observe F t (x) is of the form
t

F t (x) = ezt +〈x,vt 〉− 2 kxk ,
2

(4)

for given Itô processes (z t ), (vt ).
With this formulation of F t (x) in mind, it follows F t is non-negative, and so, we may deﬁne
(µ t ) t to be the process such that dµ t = F t dµ. It is clear that (µ t ) t is a linear-tilt localization of
µ and so, is a prelocalization of µ. The remainder of this section is devoted to showing (µ t ) t is
furthermore a stochastic localization of µ if µ is log-concave (namely we will show (L3) for this
special case), and prove some basic properties about this process useful for our analysis later.
Deﬁnition 2.6 (Log-concave measure). A measure µ on Rn is said to log-concave if it is of the
form dµ = exp(−H)dLebn for some convex function H : Rn → R ∪ {∞}
To show (µ t ) satisﬁes (L3) if µ is log-concave, we study the limiting behavior of (µ t ) as t → ∞
by considering their covariances:
Z
A t := Cov[µ t ] =

(x − a t ) ⊗ (x − a t )µ t (dx),

7

(5)

where ⊗ denotes the Kronecker product. In particular, we will show (A t )i j → 0 for all i, j ∈
{1, · · · , n} as t → ∞ allowing us to conclude (µ t ) converges weakly to some Dirac measure.
Indeed, this is a direct consequence of the following lemma.
Lemma 2.5 (Brascamp-Lieb inequality, [BL76]). Given V : Rn → R convex and K > 0, if ν is an
isotropic probability measure on Rn of the form
1

dν = Z e−V (x)− 2K kxk dLebn
2

with Z being the normalization constant, then ν satisfy the Poincaré inequality, i.e. for all differentiable ϕ,
Z
KVarν [ϕ] ≤

k∇ϕk2 dν.

With this lemma in mind, by taking ν = µ t using equation (4) and deﬁning πi (x) := x i , we have
by the Cauchy-Schwarz inequality
Z
q
q
1
(A t )i j ≤ Varµ t [πi ] Varµ t [π j ] ≤ max
k∇πk k2 dµ t
k=1,··· ,n t
Again, using equation (4), we note that any realizations of (F t (x)) is eventually decreasing in t
for all x 6= 0, implying
Z
Z
sup max

t>0 k=1,··· ,n

k∇πk k2 dµ t = sup max

t>0 k=1,··· ,n

x k2 dµ t < ∞.

Thus, by taking t → ∞ we have (A t )i j → 0 for all i, j ∈ {1, · · · , n} as claimed and we have (µ t )
satisfying (L3).
Corollary 2.6. (µ t ) converges set-wise to some Dirac measure almost everywhere. We denote
this limiting (random) Dirac measure by δa∞ where a∞ is some Rn -valued random variable.
As a result of 2.1, we have the following useful corollary.
Corollary 2.7. The massive point a∞ of the limiting Dirac measure is the limit of a t as t → ∞
and has law µ.
Proof. Since convergence implies relatively compact, applying the Dunford-Pettis theorem it
follows that any realizations of (F t ) is uniformly integrable. Thus, the result follows by the
Vitali convergence theorem.
Corollary 2.8. Similarly, taking ϕ to be any continuous
function (not necessarily bounded as
R
we have uniform integrability), deﬁning M t = ϕdµ t , (M t ) t is a martingale and
a.e.

M t −→ M∞ ∼ ϕ∗ µ
where ϕ∗ µ denotes the push-forward measure of µ along ϕ.

8

(6)

2.1.2

Discrete time linear-tilt localization

We may construct an analogous version of the linear-tilt localization for discrete time. By utilizing the little-o notation, equation (1) can be rewritten as
dµ t+h
dµ t
dµ t
(x) =
(x) + 〈x − µ̄ t , hdZ t 〉
(x) + o(h).
dµ
dµ
dµ
Hence, an discrete analog of the linear tilt localization is deﬁned as the following.
Deﬁnition 2.7 (Discrete time linear-tilt localization). Given a measure µ ∈ M (X ), the discrete
time linear-tilt localization is the sequence of random measures (µk )k deﬁned by µ0 = µ and
dµk+1 = (1 + 〈x − µ̄k , Zk 〉)dµk

(7)

for some sequence of random variables such that E[Zk | µk ] = 0 for all k ∈ N.
Using the discrete time linear-tilt localization, let us now provide an alternative construction of
the coordinate by coordinate localization.
Given µ a probability measure on {−1, 1}n , we recall that the coordinate by coordinate localization is deﬁned by “pinning” an additional random coordinate after each time step. To phrase
this as a linear-tilt localization, we take the random variables Zk to be

1+(µ̄k )Yk
 1
with probability
2
1+(µ̄k )Yk
Zk := eYk ·
(8)
1−(µ̄k )Yk
 −1
with probability
2
1−(µ̄k )Y
k

where e1 , · · · , en are the standard basis of Rn and again Y is a uniform random variable over all
permutations of [n]. Thus, the linear-tilt localization (µk ) given by this choice of (Zk ) is deﬁned
by
µk+1 (σ) = (1 + kZk k(σYk − (µk )Yk ))µk (σ)
for all k < n. Similar to before, we terminate the process at time n and so we extend the process
to all times by taking µk = µn∧k .
Let us parse this deﬁnition to see why this is equivalent to the coordinate by coordinate localization. Taking k < n, we have at the k + 1-th step, Yk+1 chooses a random axis which had not
been chosen before. Then, Zk is chosen such that for each conﬁguration σ, the probability of σYk
being ±1 is proportional the mass of µk on ±eYk . This is precisely the steps needed to construct
the coordinate by coordinate localization as conditioning on an additional axis in this case is
simply a projection on to said axis.

9

3

Application: The KLS and Thin-Shell Conjecture

As an application of stochastic localizations, we will in this section introduce the KLS and thinshell conjectures and by leveraging the linear-tilt localization, reduce the KLS conjecture (up to
a logarithmic factor) into the thin-shell conjecture, i.e. we will describe a proof of theorem 2.
The method presented in this section is due to Lee and Vempala [LV16] and reformulated in the
language of concentration by Eldan [Eld18].

3.1 Concentration
Let us quickly introduce some preliminary deﬁnitions required to state the aforementioned conjectures.
Deﬁnition 3.1 (Concentration, [Eld18]). Let µ be a measure on Rn , then µ is said to be C(inversely)-concentrated if for all 1-Lipschitz function ϕ : Rn → R,
Varµ [ϕ] = VarX ∼µ [ϕ(X )] ≤ C 2 .

(9)

µ
We denote the least possible such C by Ccon
.

Heuristically, the concentration measures the relation between µ and the Euclidean metric by
providing a numerical control for the variance of its norm. This is perhaps best illustrated by
the following proposition.
Proposition 3.1. Let X be a Rn -valued random variable. Then for all K-Lipschitz function ϕ :
Rn → R,
Var[ϕ(X )] ≤ K 2 Var[kX k2 ].
Proof. WLOG. by subtracting its expectation from X , we may assume E[X ] = 0. Let X 0 be a i.i.d.
copy of X on the same probability space. Then for all K-Lipschitz function ϕ, we have
2Var[ϕ(X )] = Var[ϕ(X ) − ϕ(X 0 )]
0

(i.i.d.)
0

= E[(ϕ(X ) − ϕ(X )) ] − E[ϕ(X ) − ϕ(X )]
2

2

= E[(ϕ(X ) − ϕ(X 0 ))2 ]

(identically distributed)

0 2

≤ K E[kX − X k ]
2

0T

(as ϕ is K-Lipschitz)
0

0

0T

= K E[X X + X X − X X − X X ]
2

T

T

= 2K 2 Var[kX k2 ] − 2K 2 Cov(X , X 0 ) = 2K 2 Var[kX k2 ].

(independence)

implying Var[ϕ(X )] ≤ K 2 Var[kX k2 ] as claimed.
With this proposition in mind, it is clear that for R-valued random variables X , its law µ has
µ
concentration Ccon
= Var[X ]. Furthermore, by considering the projection maps, it follows that
the standard Gaussian measure on Rn is 1-concentrated.
We note that the deﬁnition we are presenting here is slightly non-standard. However, utilising
a remarkable result due to Milman, we show that this deﬁnition is equivalent to the following
deﬁnitions in a speciﬁc sense.

10

Deﬁnition 3.2 (Exponential concentration, [Mil18]). Given a measure µ on Rn , we say µ has
exponential concentration if there exists some c, D > 0 such that for all 1-Lipschitz function
ϕ : Rn → R, t > 0, we have
µ(|ϕ − Eµ [ϕ]| ≥ t) ≤ ce−Dt .
(10)
µ
Fixing c = 1, we denote the largest possible D as Dexp
.

Deﬁnition 3.3 (First-moment concentration, [Mil18]). Again, given µ a measure on Rn , we say
µ has ﬁrst-moment concentration if there exists some D > 0 such that for all 1-Lipschitz function
ϕ : Rn → R, we have
1
(11)
Eµ [|ϕ − Eµ [ϕ]|] ≤ .
D
µ

We denote the largest possible D by DFM .
It is clear that exponential concentration implies ﬁrst-moment concentration. Indeed, if µ has
exponential concentration with constant D (taking c = 1), then by the tail probability formula,
Z∞
Z∞
1
µ(|ϕ − Eµ [ϕ]| ≥ t)dt ≤
e−Dt dt = .
Eµ [|ϕ − Eµ [ϕ]|] =
D
0
0
On the other hand, Milman showed that for log-concave measures on Rn , exponential concentration and ﬁrst-moment concentration are equivalent in the following sense.
Theorem 1 (Milman, [Mil08]). For all log-concave measure µ on Rn , µ has exponential conµ
µ
centration if and only if µ has ﬁrst-moment concentration. Furthermore, Dexp
' DFM where we
write A ' B if there exists universal constants C1 , C2 > 0 such that C1 A ≤ B ≤ C2 A.
With this theorem in mind, we establish the following correspondence.
Proposition 3.2. For all measures µ on Rn , we have
Exponentially concentrated =⇒ Concentrated =⇒ First-moment concentrated
p
µ
µ
µ
µ −1
µ −1
µ
µ −1
and Dexp
≤ 2(Ccon
) and (2Ccon
) ≤ DFM . Hence, if µ is log-concave, Dexp
' DFM ' (Ccon
) .
Proof. Assume ﬁrst that µ is C-concentrated. Then by the Chebyshev inequality, we have
µ(|ϕ − Eµ [ϕ]| ≥ t) ≤

1
C2
Var
[ϕ]
≤
,
µ
t2
t2

for all 1-Lipschitz ϕ. Thus, by tail probability,
Z∞
Eµ [|ϕ − Eµ [ϕ]|] =

µ(|ϕ − Eµ [ϕ]| ≥ t)dt
0

≤ inf

a>0

µ(|ϕ − Eµ [ϕ]| ≥ t)dt + C


0

≤ inf a +
a>0

Z∞

Z a

2

C
a

2
a



1
dt
t2

= 2C,

implying µ is ﬁrst-moment concentrated with respect to the constant (2C)−1 .
11



On the other hand, if µ is exponential concentration with some constant D, then again by the
tail probability,
Z∞
Z∞
p
2
2
Varµ [ϕ] =
µ((ϕ − Eµ [ϕ]) ≥ t)dt ≤
e−D t dt = 2
D
0
0
p −1
implying µ is 2D -concentrated.

3.2 Example: concentration of the Gaussian
3.3 The KLS and thin-shell conjecture
Informally, the KLS conjecture suggests that any log-concave measure on Rn admits the same
concentration as that of the Gaussian measure. However, unlike the Gaussian, as the concentration of measures is not invariant under linear functions, it is clear that the KLS conjecture would
not hold without a suitable normalization. This leads us to the following formulation of the KLS
conjecture.
n
Conjecture 1 (Kannan-Lovász-Simonovitz, [Eld18]). Denoting Mcon
the set of all log-concave
n
probability measures µ on R satisfying Varµ [T ] ≤ 1 for all 1-Lipschitz linear maps T : Rn → R,
n
there exists a universal constant C such that for all µ ∈ Mcon
, µ is C-concentrated.

We remark that C is universal in the sense that it does not depend on any parameter and in
particular is independent of the dimension n.
n
Conjecture 2 (Thin-shell, [Eld13]). Taking Mcon
as above, there exists a universal constant C
n
such that for all µ ∈ Mcon , we have
q
Varµ [k · k] ≤ C.

As the norm function is 1-Lipschitz, it is a priori that the thin-shell conjecture is weaker than
that of the KLS conjecture. On the other hand, as we shall describe in the next section, as a
consequence of the stochastic localization scheme, Eldan [Eld13] provides a reduction of the
KLS conjecture to the thin-shell conjecture up to logarithmic factors.
n
Theorem 2 (Eldan, [Eld13]). Denoting Mcon
as above, we deﬁne

n
n
Ccon
:= inf C | ∀µ ∈ Mcon
, µ is C-concentrated ,

and

¦
©
q
q
n
n
CTS
:= inf C | ∀µ ∈ Mcon
, Varµ [k · k] ≤ C = sup
Varµ [k · k],
n
µ∈Mcon

we have,
n
n
n
CTS
≤ Ccon
® CTS
log n.

The stochastic localization scheme has been wildly successful in making progress towards the
KLS conjecture. Modifying the original arguments by Eldan, Lee and Vempala [LV16] obtained
n
the bound Ccon
® n−1/4 . Further modifying their arguments, a recent breakthrough by Chen
[Che20] improves the bound providing the following theorem.
p
n
n
Theorem 3 (Chen, [Che20]). log Ccon
® log n log log n and so Ccon
= n−o(1) .
12

3.3.1

Equivalent formulation of the KLS conjecture

While we have formulated the KLS conjecture using the language of concentration, the conjecture itself is originally formulated as an isoperimetric problem. The isoperimetric problem is
the problem in ﬁnding the set of unit volume with minimum surface area. In the case of the
Rn equipped with the Lebesgue measure, we have known since the ancient Greeks [Bl05] that
the solution is the unit ball. With this in mind, it is natural for us to generalize the problem for
arbitrary measures.
Deﬁnition 3.4 (Minkowski’s boundary measure). Given a measure µ on Rn and a Borel set
A ⊆< Rn , the Minkowski’s boundary measure of A,
µ+ (∂ A) := lim inf
ε↓0

µ(Aε ) − µ(A)
.
ε

where Aε := {x ∈ Rn | dist(x, A) ≤ ε} is the ε-thickening of some Borel set A.
The isoperimetric problem for the measure µ then becomes the problem of ﬁnding the set A
satisfying µ(A) = 1 with minimum µ+ (∂ A).
Deﬁnition 3.5 (Cheeger’s inequality, [Mil08]). Given a measure µ on Rn , we say µ satisfy
Cheeger’s inequality if there exists some D such that for all A,
µ(A) ∧ µ(Ac ) ≤ Dµ+ (A).
We call the largest such D the inverse Cheeger’s constant (or the inverse isoperimetric constant)
µ
and denote it by DC .
With this, the KLS conjecture can be reformulated as the following.
n
Conjecture 3 (KLS, [Eld13]). Denoting Miso
the set of all log-concave and isotropic (i.e.
EX ∼µ [X ] = 0 and CovX ∼µ (X ) = id) probability measures µ on Rn , there exists a universal
n
constant D such that for all µ ∈ Miso
, µ satisfy the Cheeger’s inequality with constant D.

The equivalence of the reformulation follows by completing theorem 3.2 with two additional
equivalences.
Theorem 4 (Milman, [Mil08]). For all log-concave measure µ on Rn , the following are equivalent
µ
• µ has exponential concentration with constant Dexp
.
µ

• µ has ﬁrst-moment concentration with constant DFM .
µ

• µ satisfy the Cheeger’s inequality with constant DC .
• µ satisfy the Poincaré Rinequality: there exists some D > 0 such that for all differentiable
ϕ : Rn → R satisfying ϕdµ = 0, we have
Z
D · Varµ [ϕ] ≤
µ

We denote the largest such D by DP .
13

k∇ϕk2 dµ.

µ

µ

µ

µ
Furthermore, Dexp
' DFM ' DP ' DC .

With this theorem and proposition 3.2 in mind, it is clear that the KLS conjecture can be instead
formulated with any of these inequalities instead. Thus, the KLS conjecture can also be phrased
using the constant provided by the Poincaré inequality.
n
Conjecture 4 (KLS, [Eld13]). Denoting Miso
as above, there exist a universal constant D such
n
that for all µ ∈ Miso , µ satisfy the Poincaré inequality with constant D.

We remark that isotropic measures satisfy the normalization condition in 1. Indeed, if T : Rn →
R is a 1-Lipschitz linear function, i.e. is of the form v 7→ w T v + d for some w ∈ S n−1 and d ∈ R,
then we have

 n
n
n
X
X
X
w i w j CovX ∼µ (X i , X j ) =
w2i = 1,
Varµ [T ] = VarX ∼µ
wi X i + d =
i, j=1

i=1

i=1

as CovX ∼µ (X ) = id.

3.4 Reduction of KLS to thin-shell
We will now present a proof of theorem 2. As a high level overview, recall that the linear-tilt
localization of a given measure is a measure-valued martingale for which the original measure
is recovered in the limit. Then, as the concentration of the measure relates to the covariance of
said measure, we will stop the martingale before the covariance grows too large. This allows
us to analyze the martingale in a more tractable manner. However, as the the sequence is a
martingale, some properties are invariant in time and hence allowing us to conclude that these
properties also hold for the original measure.
We recall the goal of theorem 2 is to control Varµ [ϕ] by a logarithmic factor of Varµ [k · k]. As
translating the barycenter of µ does not affect its variance, we may assume µ has its barycenter
µ at the origin. Furthermore, we may assume µ is supported on Bn (0) ⊆ Rn with Bn (0) the ball
at the origin of radius n. Thus, we also have
supp µ t = supp F t µ ⊆ supp µ ⊆ Bn (0)
for all t > 0.
Fix ϕ : Rn → R some 1-Lipschitz function and let (M t ) be the martingale as described above and
a.e.
in particular we recall equation (2.7) and so, Varµ [ϕ] = Var[M∞ ] where M t −→ M∞ . Hence,
for all t > 0, by the martingale property we have


2
Var[M t ] + E[Var[M∞ | F t ]] = (E[M t2 ] − E[M t ]2 ) + E E[M∞
| F t ] − E[M∞ | F t ]2
2
= E[M t2 ] + (E[E[M∞
| F t ]] − E[M t2 ])
2
= E[M∞
] = Var[M∞ ],

where the second equality follows as E[M t ] = E[M∞ ] = Eµ [ϕ] = 0 as a linear map
On the other hand, as (M t ) is a martingale, M t2 − [M ] t is also a martingale implying E[M t2 ] =
E[M ] t and so Var[M t ] = E[M t2 ] − E[M t ]2 = E[M ] t − µ2 = E[M ] t . Hence, combining this with
the above, we obtain the bound
Varµ [ϕ] = Var[M∞ ] = Var[M t ] + E[Var[M∞ | F t ]] = E[M ] t + E[Varµ t [ϕ]].
14

(12)

explain

Now, observing that ϕ is 1-Lipschitz implies k∇ϕk2 ≤ 1, we have by lemma 2.5 the bound
Varµ t [ϕ] ≤ t −1 (in fact Varµ t [ϕ] ≤ t −1 ∧ n2 as we have assumed supp µ t ⊆ Bn (0)). Thus, the
second term E[Varµ t [ϕ]] is bounded by t −1 . With this in mind, by choosing an appropriate
random time τ to stop the process such that E[M ]τ is nicely bounded, the result follow by
bounding E[τ−1 ]. We dedicate the remainder of this section to describe said procedure in detail.
3.4.1

Differential of the quadratic variation

To bound the term E[M ]τ we will compute its differential and bound it sufﬁciently such that
we reobtain a bound for [M ]τ after integration. We will show d[M ] t is bounded by a quantity
concerning A t . This should not be at all surprising as both d[M ] t and A t describes the variation
of M t in a inﬁnitesimal time neighborhood of t.
We compute
Z

Z

dM t = d

ϕ(x)F t (x)µ(dx) =

ϕ(x)〈x − a t , dWt 〉µ t (dx)

Z



=

ϕ(x)(x − a t )µ t (dx), dWt

and so, by considering the component-wise quadratic variation, we have
Z

Then, denoting θ the vector


R

2

ϕ(x)(x − a t )µ t (dx)

d[M ] t =

(13)

ϕ(x)(x − a t )µ t (dx) normalized to have norm 1, so

Z
θ,

dt.



Z

ϕ(x)(x − a t )µ t (dx) =

ϕ(x)(x − a t )µ t (dx)

we observe,

d[M ] t = θ ,

Z

2
ϕ(x)(x − a t )µ t (dx)


dt = θ ,

Z
=

2
(ϕ(x) − a t )(x − a t )µ t (dx)

dt

2
(ϕ(x) − a t )〈θ , x − a t 〉µ t (dx)

Z
≤

Z

dt

 Z
(ϕ(x) − a t ) µ t (dx)

2

Z
= Varµ t [ϕ]


〈θ , x − a t 〉 µ t (dx) dt

2

(14)


⊗2

θ (x − a t ) θ µ t (dx) dt = Varµ t [ϕ](θ T A t θ )dt
T

≤ Varµ t [ϕ]kA t kop dt.
where the inequality follows by the Cauchy-Schwarz inequality and k · kop denotes the operator
norm. Thus, as we know Varµ t [ϕ] ≤ t −1 , the problem is now reduced to that of bounding kA t kop .

15

3.4.2

Analysis of the covariance matrix

As demonstrated in section 2.1.1, we know the limiting behavior of the covariance matrices,
namely A t → 0 point-wise as t → ∞. This was important for us to establish the existence of the
limit of (a t ) and (M t ). However, as shown above, we now require some quantitative bounds for
the operator norm of A t . For this purpose, we ﬁrst compute some useful properties of A t .
Observing
Z

Z
dF t (x)µ(dx) =

we have

Z
〈x − a t , dWt 〉µ t (dx) =

Z
da t = d

= 0,

Z
xdF t (x)µ(dx) =

Z
=

xµ t (dx) − a t , dWt

Z
x F t (x)µ(dx) =



(x − a t )dF t (x)µ(dx)

Z

(15)
⊗2

(x − a t )〈x − a t , dWt 〉F t (x)µ(dx) =

(x − a t ) dWt µ t (dx) = A t dWt

where the second to last equality used the fact that v〈v, w〉 = v ⊗2 w for any appropriate v, w.
Similarly, computing using Itô’s formula, we have
Z
(x − a t )⊗2 F t (x)µ(dx)

dA t = d
Z
=

(16)

(x − a t )⊗2 dF t (x) + F t (x) d(x − a t )⊗2
− 2(x − a t ) ⊗ d[a t , F t (x)] t + F t (x)d[a t ] t µ(dx).

The second term vanishes as
z
Z

Z
F t (x) d(x − a t )⊗2 µ(dx) = −2da t ⊗

=0

}|

{

(x − a t )µ t (dx) = 0.

Also, by equation (15), da t = A t dWt implying d[a t ] t = A2t dt. Finally, as both (a t ) and (F t (x))
are martingales, d[a t , F t (x)] t = F t (x)A t xdt and the third term becomes
Z
Z

−2

(x − a t ) ⊗ d[a t , F t (x)]µ t (dx) = −2A t

(x − a t ) ⊗ xµ t (dx) dt



= −2A t 


A

z
Z

}|t

{

(x − a t )⊗2 µ t (dx) +

z
Z

=0

Hence, combining these and equation (2) together in (16), we have
Z
(x − a t )⊗2 〈x − a t , dWt 〉µ t (dx) − A2t dt
16

{




(x − a t )µ t (dx) ⊗a t 
 dt

= −2A2t dt.

dA t =

}|

However, since we wish to bound A t from above, as the drift term −A2t dt only contributes negaR
tively, an upper bound for the process of the form (x −a t )⊗2 〈x −a t , dWt 〉µ t (dx) is also sufﬁcient
for A t . Hence, we proceed by ignoring the drift term and redeﬁne the process A t such that
Z
(x − a t )⊗2 〈x − a t , dWt 〉µ t (dx).

dA t =

(17)

With this justiﬁcation, we now proceed to bound the operator norm of this new A t . In particn
ular, as A t is symmetric, we recall that kA t kop = maxi=1,··· ,n λi (t) = k(λi (t))i=1
k∞ where λi (t)
denotes the distinct eigenvalues of A t . Hence, it sufﬁces to ﬁnd a bound for the potential
Φα (t) =

n
X

|λi (t)|α = k(λi (t))ni=1 kαα

(18)

i=1

for some α > 0. Furthermore,
as A t is positive semi-deﬁnite, λi (t) ≥ 0 for all i = 1, · · · , n and
Pn
thus we have Φα (t) = i=1 λi (t)α . Again, to proceed, we will attempt to compute dΦα (t) at
some t = t 0 > 0 utilizing the following lemma.
Lemma 3.3. If A = [ai j ] is a diagonal matrix with distinct eigenvalues λi , · · · , λn , then for all
i, j, k, l, m ∈ 1, · · · n, we have
∂λ

• ∂ a jki = δi j δik ;
∂ 2λ

• whenever i 6= j, ∂ a2i = 2(λi − λ j )−1 ;
ij

∂ 2λ

• and for j 6= l, k 6= m or i 6= j and i 6= k, ∂ a jk ∂ ai l m = 0,
where δi j denotes the Kronecker delta function.
As this lemma requires the matrix to be diagonal, denoting e1 , · · · , en as the normalized eigenbasis of A t 0 (they are in fact orthonormal as A t 0 is positive semi-deﬁnite), we will consider A t
with respect to this basis by considering the entries
ai j (t) := 〈ei , A t e j 〉.
Using equation (17), we compute
 Z

 
⊗2

dai j (t) = ei ,

(x − a t ) 〈x − a t , dWt 〉µ t (dx) e j

Z
=


⊗2

〈ei , (x − a t ) e j 〉(x − a t )µ t (dx), dWt

= 〈ξi j , dWt 〉

R
where we introduce the notation ξi j = 〈ei , (x − a t )⊗2 e j 〉(x − a t )µ t (dx). Thus, combining this
with lemma 3.3, denoting λi = λi (t 0 ), we have by Itô’s formula
dλi (t) =

n
X
∂λ
j,k=1

∂ 2 λi
1 X X
d[a jk , alm ] t
2 j,k=1 l,m=1 ∂ a jk ∂ alm
n

i

∂ a jk

da jk (t) +

= 〈ξii , dWt 〉 +

X d[ai j ] t
j6=i

λi − λ j
17

n

= 〈ξii , dWt 〉 +

X kξi j k2
j6=i

λi − λ j

dt.

(19)

at t = t 0 . As a result, it is also clear that d[λi (t)] t 0 = kξii k2 dt.
Again applying Itô’s formula, we may ﬁnally compute
dΦα (t) =

n
X
∂ Φα
i=1

∂ λi

1 X ∂ 2 Φα
d[λi , λ j ] t
2 i, j=1 ∂ λi ∂ λ j t=t 0
n

t=t 0

dλi (t) +

n
X
1
λα−2
d[λi (t)] t
α(α
−
1)
λα−1
dλ
(t)
+
i
i
i
2
i=1
i=1
!
n
n
X kξi j k2
X
X
1
α−1
λi
〈ξii , dWt 〉 +
λα−2
d[λi (t)] t
=α
dt + α(α − 1)
i
λ
−
λ
2
i
j
i=1
i=1
j6=i
*
+
n
n
X
X
X
kξi j k2
1
α−1
α−2
2
α−1
=α
λi
dt + α(α − 1)
λi kξii k dt + α
λi ξii , dWt
λi − λ j
2
i=1
i=1
i6= j
|
{z
}

=α

n
X

=:vt

λα−1 − λα−1
j
2 i

=

1 X
α
kξi j k
2 i6= j

≤

n
X
X
1
1
kξi j k2 (λi ∨ λ j )α−2 dt + α(α − 1)
α(α − 1)
λi (t)α−2 kξii k2 dt + 〈vt , dWt 〉
2
2
i=1
i6= j

=

n
n
X
X
1
α(α − 1)
kξi j k2 (λi ∨ λ j )α−2 dt + 〈vt , dWt 〉 ≤ α2
kξi j k2 λα−2
dt + 〈vt , dWt 〉,
i
2
i, j=1
i, j=1

λi − λ j

n
X

1
dt + α(α − 1)
λi (t)α−2 kξii k2 dt + 〈vt , dWt 〉
2
i=1

where the ﬁrst inequality holds as
λα−1
− λα−1
i
j
λi − λ j

= λα−2
+ λα−3
λ j + · · · + λα−2
≤ (α − 1)(λi ∨ λ j )α−2 .
i
i
i

Thus, we have shown
dΦα (t) ≤ α2

n
X

λi (t)α−2

i=1

where vt := α

n
X

kξi j k2 dt + 〈vt , dWt 〉

(20)

j=1

Pn

α−1
ξii .
i=1 λi

By recalling that our goal is to bound kA t kop from above (c.f. equation (12) and (14)), we may
assume without loss of generality that kA t kop ≥ 1. Thus, applying the reverse Cauchy-Schwarz
inequality to equation (20), we have
dΦα (t) ≤ 2α2

n
X

λi (t)α−2

n
X
j=1

i=1

≤ 2α2 kA t k2op

n
X

λi (t)α−2

n
X
i=1

λi (t)α

n
X

kξi j k2 dt + 〈vt , dWt 〉

j=1

i=1

® 2α2

kξi j k2 dt + 〈vt , dWt 〉

n
X

kξi j k2 dt + 〈vt , dWt 〉.

j=1

18

Thus, deﬁning K t := supi

Pn

2
j=1 kξi j k , we have the bound

dΦα (t) ® 2α2 K t Φα (t)dt + 〈vt , dWt 〉.
3.4.3

(21)

Stopping the process early

As outlined in the beginning of this section, we will stop the process early in order to provide
a bound for the right hand side of equation (12). By observing equation (14), we hypothesize
that we should stop the process once kA t kop grows too large. As a result we deﬁne the stopping
time
τ := inf{t > 0 | kA t kop > 2} ∧ 1.
By the optional stopping theorem we have
Zτ
[M ]τ =

d[M ] t ≤

≤2
∧n2
Z τ z≤t −1
}| { z }| {

0

Zτ

≤2

Varµ [ϕ] kA t kop dt

0

t

−1

Z1
t −1 ∧ n2 dt = 2 + 4 log n.

∧ n dt ≤ 2
2

0

0

Combining this with equation (12), we obtain
Varµ [ϕ] ≤ 2 + 4 log n + E[τ−1 ],

(22)

and it remains to ﬁnd an upper bound for E[τ−1 ]. Observing that t < τ whenever Φα (t) < 2α ,
we deﬁne the σ the ﬁrst time for which the potential Φα (t) reaches 2α , namely
σ := inf{t > 0 | Φα (t) = 2α },
we have σ−1 ≥ τ−1 and so it sufﬁces to bound σ from below.
For simplicity, let us ignore the stochastic term in equation (21) and regard it as an ODE. Then,
by Gronwall’s inequality, if we can ﬁnd some constant K such that K t ≤ K for all t ≤ τ, we have
the bound
2
S t ≤ ne2α K t .
Thus, substituting σ into the above, we have
2α = Sσ ≤ ne2α Kσ
2

implying

α log 2 − log n
≤ σ ≤ τ.
2α2 K
Then, taking α = 10K log n, it is easy to check that
α log 2 − log n
1
≤
10K log n
2α2 K
implying E[τ−1 ] ≤ 10K log n. Of course, this deduction only holds while ignoring the stochastic
term 〈vt , dWt 〉. Nonetheless, this is justiﬁed as one can show that kvt k2 is bounded αΦα (t) and
so the same analysis holds by applying the stochastic Gronwall’s inequality (c.f. second part of
lemma 34 in [LV18]).
Finally, to ﬁnd a bound for (K t ), we employ the following lemma.
19

Maybe not
ignore the
martingale
term if we
want a complete proof

n
Lemma 3.4 (Lemma 1.6 in [Eld13]). Denoting CTS
as in theorem 2, there exists a constant C
such that for any log-concave, isotropic probability measure µ, we have
n
X

sup
θ ∈S n−1 i, j=1

EX ∼µ [〈X , ei 〉〈X , e j 〉〈X , θ 〉]2 ≤ C

n
X
(C n )2
TS

k=1

k

,

where {e1 , · · · , en } is any orthonormal basis on Rn .
Recalling that

ξi j = EX +a t ∼µ t [〈ei , X ⊗2 e j 〉X ] = EX +a t ∼µ t [〈X , ei 〉〈X , e j 〉X ],

we have by Parseval’s identity
K t = sup
i

n
X

i

j=1

= sup
i

n X
n
X

n
X

kEX +a t ∼µ t [〈X , ei 〉〈X , e j 〉X ]k2

j=1

EX +at ∼µ t [〈X , ei 〉〈X , e j 〉X ], ek

2

j=1 k=1
n
X

= sup
i

kξi j k = sup
2

EX +a t ∼µ t [〈X , ei 〉〈X , e j 〉〈X , ek 〉]2

j,k=1

≤ sup

n
X

θ ∈S n−1 i, j=1

EX +at ∼µ [〈X , ei 〉〈X , e j 〉〈X , θ 〉]2 .

We note that we cannot direct apply lemma 3.4 at this point since the measure µ t might not
be isotropic. Hence, to be able to use the lemma, we need to normalize the covariance of µ t .
Namely, taking X + a t ∼ µ t , we deﬁne Y = A−1/2 X which by construction is isotropic. Thus, by
observing that
EX +a t ∼µ [〈X , ei 〉〈X , e j 〉〈X , θ 〉]2 ≤ kA t k3op EX +a t ∼µ [〈Y, ei 〉〈Y, e j 〉〈Y, θ 〉]2 ,
we have
K t ≤ sup

θ ∈S n−1

n
X

EX +a t ∼µ [〈X , ei 〉〈X , e j 〉〈X , θ 〉]2

i, j=1

≤ kA t k3op

n
X

sup
θ ∈S n−1 i, j=1

EX +a t ∼µ [〈Y, ei 〉〈Y, e j 〉〈Y, θ 〉] ≤ 8C
2

n
X
(C n )2

(23)

TS

k=1

k

where the last inequality follows as kA t kop ≤ 2 for all t < τ.
At last, combining equation (23) and (22), we have


Θ(log n)
z }| {
n


X
1 n 2

n
Varµ [ϕ] ≤ 2 + log n 4 + 80C
log n)2 )
(CTS )  = Θn ((CTS
k


k=1
implying there exists a constant R > 0 such that for all 1-Lipschitz ϕ,
n
n
n
i.e. µ is RCTS
log n-concentrated and so, Ccon
≤ RCTS
log n as required.
20

Æ

n
Varµ [ϕ] ≤ RCTS
log n,

4

Application: Markov Mixing

An application of stochastic localizations is used to prove mixing bounds for Markov processes.
Expanding on the work of Anari, Liu and Oveis in [ALG20], Chen and Eldan in [CE22] established a framework in which mixing bounds of a special class of Markov processes arises,
namely Markov chains associated with stochastic localizations. We will in this section present
this framework and describe its application to the Glauber dynamics.

4.1 Mixing bounds
The motivation for Markov mixing bounds fundamentally comes from sampling. Suppose we
wish to sample from some probability distribution µ. A common method to achieve this to
through the use of the Markov chain Monte Carlo (MCMC):
Theorem 5. Given (X n ) an irreducible positively recurrent homogenous Markov process on X
with stationary distribution µ, for any ϕ : X → R integrable,
Z
n
1X
lim
ϕ(X k ) =
f dµ
n→∞ n
k=1
almost everywhere.
With this theorem in mind, MCMC allows us to sample µ by sampling from (X n ) instead. It is
in general not difﬁcult to come up with such Markov processes, although it is often difﬁcult to
show its rate of convergence. This motivates the notion of mixing bounds which quantiﬁes the
time for which the Markov process takes before its law is approximately stationary.
Deﬁnition 4.1 (Total variation mixing time). Given a probability measure ν ∈ M (X ), a Markov
kernel K with stationary distribution µ and some ε > 0, the ε-total variation mixing time is
deﬁned as
t mix (P, ε, µ) := inf{t ≥ 0 | kP t ν − µkTV < ε},
Furthermore, we denote
t mix (P, ε) = sup t mix (P, ε, δ x )
x∈X

the worst mixing time starting at a point.
A standard method of analyzing the mixing times of Markov chains is through the use of the
spectral gap.
Deﬁnition 4.2 (Spectral gap, [Lev17]). The spectral gap of a Markov kernel K is deﬁned to be

gap(K) := 1 − sup{λ | λ is an eigenvalue of K, λ 6= 1}.
It is not difﬁcult to show that
R
Z
ϕKϕdµ
1
gap(K) = inf 1 − R
(ϕ(x) − ϕ( y))2 K(x, d y)µ(dx),
= inf
2 dµ
ϕ:X
→R
ϕ:X
→R
2Var
[ϕ]
ϕ
µ
R

(24)

ϕdµ=0

R
where µ is the stationary measure of K and Kϕ = ϕ( y)K(·, d y). We will take equation (24)
to be the deﬁning property of the spectral gap in the case K is deﬁned on a general state space.
21

Fix!

Theorem 6 ([Lev17]). Given a reversible and irreducible Markov chain with kernel K on the
state space X with stationary distribution µ, denoting µmin = inf x∈X µ(x), we have


¡

 ¤
1
1
1
1
t mix (K, ε) ≤
log
+ log
.
gap(K) 2
µmin
2ε
We remark that this inequality is only meaningful whenever µmin > 0 and thus, this theorem is
only meaningful for Markov chains on ﬁnite state space (and we can replace inf with min).
A similar bound can also be established using the modiﬁed log-Sobolev inequality (MLSI).
Deﬁnition 4.3 (Entropy, [CLV20]). Given ϕ : X → R≥0 and a measure µ, we deﬁne the entropy
of ϕ with respect to µ to be


 Z
Z
Z

1
Entµ [ϕ] := Eµ ϕ log
ϕ = ϕ log ϕdµ − ϕdµ log
ϕdµ .
Eµ [ϕ]
Deﬁnition 4.4.
4.1.1

TODO

Ising model and Glauber dynamics

Deﬁnition 4.5 (Ising model). Given a graph G = (V, E), β > 0 and h ∈ R, the Ising model on
G with inverse temperature β and external ﬁeld h is the probability measure µβ,h on {−1, 1}V
deﬁned such that for all σ ∈ {−1, 1}V ,
(
)
X
X
1
µβ,h (σ) := exp β
σx σ y + h
σx
Z
x y∈E
x∈V
where Z > 0 is the normalizing constant.
Heuristically, the Ising model measures the probability that a graph is in a speciﬁc conﬁguration
of up and down spins in which neighboring vertices are more likely to have the same spin. This
“likeliness” is controlled by β in which a larger β means that neighboring vertices are more likely
to align.
As illustrated by theorem 5, in order to sample from the Ising model, we can construct a Markov
chain which has the Ising model as its stationary distribution. One such Markov chain is known
as the Glauber dynamics.
Deﬁnition 4.6 (Glauber dynamics). Given a measure µ of {−1, 1}n , the Glauber dynamics of µ
is the Markov chain with kernel
X
µ(σ2 )
µ(σ1 )
1
1
K(σ1 , σ2 ) := 1{kσ1 −σ2 k1 =1}
+
1
,
(25)
1
2
{σ =σ }
n µ(σ1 ) + µ(σ2 )
n kσ̃−σ1 k =1 µ(σ1 ) + µ(σ̃)
1

Pn
1

where we deﬁne kσ1 − σ2 k1 := 2

1
2
1
2
n
i=1 |σi − σi | for all σ , σ ∈ {−1, 1} .

Parsing this deﬁnition, we see that the Glauber dynamics is the Markov chain such that, starting
at a conﬁguration σ1 ∈ {−1, 1}n , the conﬁguration at the next time step either remains the same
or change at one vertex. Furthermore, the probability of this occurring is weighted according
to µ. As we hoped, the Glauber dynamics of the Ising model µβ,h has µβ,h as its stationary
distribution.
22

4.2 Dynamics of stochastic localizations
As alluded to previously, one may associate a Markov process at each time step of a stochastic localization process for which the original process is stationary. We will in this section deﬁne these
Markov processes and show that the Glauber dynamics can be constructed using this method.
Deﬁnition 4.7 (Markov process associated with a stochastic localization, [CE22]). Let (µ t ) t≥0
be a stochastic localization of µ such that µ t is absolutely continuous (almost everywhere) with
respect to µ for all t. For all τ > 0, we deﬁne the dynamics associated with (µ t ) t at τ to be the
Markov process with kernel


dµτ
(x)µτ (A)
K(x, A) := EP
dµ
for all x ∈ X , A ∈ Σ.
As alluded by the notation, rather than a deterministic time τ, τ can be taken to be an appropriate stopping time. In this case, the theorems below will remain to hold by invoking the optional
stopping theorem whenever necessary.
This is indeed a kernel since for each x ∈ X , as EP [µτ ] = µ by (L2),


dµτ
dµ
d
K(x, Ω) = EP
(x) =
EP [µτ ](x) =
(x) = 1
dµ
dµ
dµ
where the third equality follows by the uniqueness of the Radon-Nikodym derivative as for all
A ∈ Σ, we have
Z
Z



dµτ
dµτ
EP
dµ = EP
dµ = EP [µτ ](A).
dµ
dµ
A
A
Proposition 4.1. The Markov process associated with a stochastic localization (µ t ) t≥0 of µ is
reversible and has stationary distribution µ.
Proof. Taking ϕ : X 2 → R integrable, we have by Fubini’s theorem
Z
Z


dµτ
ϕ(x, y)K(x, d y)µ(dx) = ϕ(x, y)EP
(x)µτ (d y) µ(dx)
dµ
X2

Z
dµτ
(x)µ(dx)
= EP
ϕ(x, y)µτ (d y)
dµ
Z

= EP

ϕ(x, y)µτ (d y)µτ (dx) .

Similarly, by the same calculation,
Z
X2

Thus,

Z

ϕ(x, y)K( y, dx)µ(d y) = EP

Z


ϕ(x, y)µτ (d y)µτ (dx) .

Z
ϕ(x, y)K(x, d y)µ(dx) =
X2

ϕ(x, y)K( y, dx)µ(d y)
X2

for any integrable ϕ : X 2 → R implying K is reversible.
23

(26)

On the other hand, for all A ∈ Σ, we compute using the martingale property
Z
Z

Z



dµτ
dµτ
Kµ(A) = K(x, A)µ(dx) = EP
(x)µτ (A) = EP µτ (A)
dµ
dµ
dµ
= EP [µτ (A)µτ (Ω)] = EP [µτ (A)] = µ(A)
implying µ is the stationary measure of K.
Proposition 4.2. Taking K to be the kernel of the Markov process associated with a stochastic
localization (µ t ) t≥0 of µ at time τ, we have

gap(K) =

inf

ϕ:X →R

E[Varµτ [ϕ]]
Varµ [ϕ]

.

Proof. By equation (26) (where we take ϕ(x, y) = ϕ(x)ϕ( y)), we have
Z
Z
2 
X2

ϕ(x)ϕ( y)K(x, d y)µ(dx) = EP

X

ϕdµτ

,

for any integrable ϕ : X → R. On the other hand, we observe
Z
Z
Z
ϕ( y)2 K(x, d y)µ(dx) =

(Kϕ 2 )(x)µ(dx) =

ϕ(x)2 (Kµ)(dx) =

(27)

Z
ϕ(x)2 µ(dx)

X2

as µ is the stationary measure of K. Thus, for any integrable ϕ : X → R, by substituting the
above two equations, we have
Z
1
(ϕ(x) − ϕ( y))2 K(x, d y)µ(dx)
2Varµ [ϕ] X 2
Z
Z
Z

1
=
ϕ(x)2 µ(dx) − 2 ϕ(x)ϕ( y)K(x, d y)µ(dx) + ϕ( y)2 K(x, d y)µ(dx)
2Varµ [ϕ]
Z
Z
2 
1
2
=
ϕdµτ
ϕ dµ − EP
Varµ [ϕ]
X
Z
Z
2 
E[Varµτ [ϕ]]
1
=
EP
ϕdµτ
.
ϕ 2 dµτ −
=
Varµ [ϕ]
Varµ [ϕ]
X
Hence, recalling the equivalent form of the spectral gap as described by (24), the result follows
by taking inﬁmum on both sides.
This proposition has a nice intuitive interpretation. By recalling that the limit of a stochastic
localization as t → ∞ is a Dirac measure, we may imagine a stochastic localization zooms in
(in t) towards a region containing the massive point. Then, the spectral gap of the associated
Markov process at time τ is simply the smallest proportion of the local variation around this
zoomed in region at time τ to that of the global variation. This is achieved by a test function
with minimal variation within this region and maximal variation outside of it.

24

With regards to theorem 6, in the case µ has full support on the ﬁnite state space X (e.g. in the
setting of Glauber dynamics) the above proposition provides a method for computing an upper
bound for the mixing time. In particular, should the stochastic localization (µk )k satisfy
E[Varµk+1 [ϕ] | µ t ] ≥ (1 − ε)Varµk [ϕ]
for given ε > 0 and any integrable function ϕ : X → R, we have the telescoping product
 k

Y E[Varµ [ϕ] | µi−1 ]
E[Varµk [ϕ]]
i
=E
≥ (1 − ε)k .
Varµ [ϕ]
Var
[ϕ]
µ
i−1
i=1
Hence, we have the bound

gap(K)−1 ≤ (1 − ε)−k

which immediately provides an upper bound for the mixing time of K in light of theorem 6. This
motivates the following deﬁnition.
Deﬁnition 4.8 (Approximate conservation of variance, [CE22]). A stochastic localization process (µk )k is said satisfy conserve (κk )-variance up to time n if for any integrable function
ϕ : X → R, 1 ≤ k ≤ n,
E[Varµk+1 [ϕ] | µ t ] ≥ (1 − κk )Varµk [ϕ].
By the same computation above, if (µk )kQconserves (κk )-variance up to time n, then it associated
n
dynamics has a spectral gap of at least i=1 (1 − κi ).

4.3 Glauber dynamics as an associated Markov process
As alluded to in section 2, Glauber dynamics can be constructed as an associated Markov chain
of the coordinate by coordinate localization. Namely, taking µ ∈ M ({−1, 1}n ) and τ = n − 1,
we will show the associate Markov kernel


µn−1 (σ1 )µn−1 (σ2 )
E
= K(σ1 , σ2 )
µ(σ1 )
for all σ1 , σ2 ∈ {−1, 1}n where K(σ1 , σ2 ) as deﬁned by equation (25).
First, taking σ1 , σ2 ∈ {−1, 1}n such that kσ1 − σ2 k = 1, say σ1 and σ2 differs at the m-th
coordinate, we have




n
µn−1 (σ1 )µn−1 (σ2 )
µn−1 (σ1 )µn−1 (σ2 )
1X
E
=
E
Y
=
k
.
n
µ(σ1 )
n k=1
µ(σ1 )
Now, if Yn = k 6= m, the conﬁguration is ﬁxed at the m-th coordinate. However, as σ1 and σ2
differs at the m-th coordinate, either µn−1 (σ1 ) = 0 or µn−1 (σ2 ) = 0. Thus, all but the m-th term
in the above sum vanishes and we have the kernel equals


µn−1 (σ1 )µn−1 (σ2 )
1
Yn = m
= E
n
µ(σ1 )


µn−1 (σ1 )µn−1 (σ2 )
1
= E
1{supp µn−1 ={σ1 ,σ2 }} Yn = m
n
µ(σ1 )


P(supp µn−1 = {σ1 , σ2 })
µn−1 (σ1 )µn−1 (σ2 )
1
2
=
E
Yn = m, supp µn−1 = {σ , σ }
n
µ(σ1 )

25

Then, substituting in the following equalities:
P(supp µn−1 = {σ1 , σ2 }) = µ(σ1 ) + µ(σ2 ),
and
E[µn−1 (σ1 )µn−1 (σ2 ) | Yn = m, supp µn−1 = {σ1 , σ2 }]
=E[µn−1 (σ1 )µn−1 (σ2 ) | supp µn−1 = {σ1 , σ2 }]
=

µ(σ1 )

µ(σ2 )

µ(σ1 ) + µ(σ2 ) µ(σ1 ) + µ(σ2 )

we have


µn−1 (σ1 )µn−1 (σ2 )
µ(σ1 ) + µ(σ2 )
µ(σ1 )
µ(σ2 )
µ(σ2 )
1
E
=
=
µ(σ1 )
nµ(σ1 )
µ(σ1 ) + µ(σ2 ) µ(σ1 ) + µ(σ2 )
n µ(σ1 ) + µ(σ2 )
which is precisely the kernel of the Glauber dynamics of two neighboring conﬁgurations. On the
other hand, if kσ1 − σ2 k > 1, then


µn−1 (σ1 )µn−1 (σ2 )
E
=0
µ(σ1 )
as µn−1 have ﬁxed all but one coordinate. Thus, the dynamics associated with the coordinate is
precisely the Glauber P
dynamics (we don’t need to check the case σ1 = σ2 as they are kernels
and so K(σ, σ) = 1 − σ̃6=σ K(σ, σ̃)).

26

References
[ALG20] Nima Anari, Kuikui Liu, and Shayan Oveis Gharan. Spectral independence in highdimensional expanders and applications to the hardcore model, 2020.
[BL76]

Herm Jan Brascamp and Elliott H Lieb. On extensions of the brunn-minkowski and
prékopa-leindler theorems, including inequalities for log concave functions, and with
an application to the diffusion equation. Journal of Functional Analysis, 22(4):366–
389, 1976.

[Bl05]

Viktor Blåsjö. The isoperimetric problem.
112(6):526–566, 2005.

[CE22]

Yuansi Chen and Ronen Eldan. Localization schemes: A framework for proving mixing
bounds for markov chains, 2022.

The American Mathematical Monthly,

[Che20] Yuansi Chen. An almost constant lower bound of the isoperimetric coefﬁcient in the
kls conjecture, 2020.
[CLV20] Zongchen Chen, Kuikui Liu, and Eric Vigoda. Optimal mixing of glauber dynamics:
Entropy factorization via high-dimensional expansion, 2020.
[Eld13] Ronen Eldan. Thin shell implies spectral gap up to polylog via a stochastic localization
scheme. Geometric and Functional Analysis, 23(2):532–569, mar 2013.
[Eld18] Ronen Eldan. Lecture notes - from stochastic calculus to geometric inequalities, 2018.
[Lev17] David Asher Levin. Markov chains and mixing times / David A. Levin, Yuval Peres ; with
contributions by Elizabeth L. Wilmer. American Mathematical Society, second edition.
edition, 2017.
[LV16]

Yin Tat Lee and Santosh S. Vempala. Eldan’s stochastic localization and the kls conjecture: Isoperimetry, concentration and mixing, 2016.

[LV18]

Yin Tat Lee and Santosh S. Vempala. The kannan-lovász-simonovits conjecture, 2018.

[Mil08] Emanuel Milman. Uniform tail-decay of lipschitz functions implies cheeger’s isoperimetric inequality under convexity assumptions. Comptes Rendus Mathematique,
346(17):989–994, 2008.
[Mil18] Emanuel Milman. On the role of convexity in isoperimetry, spectral-gap and concentration. 2018.
[Øks03] Bernt Øksendal. Stochastic Differential Equations, pages 65–84. Springer Berlin Heidelberg, Berlin, Heidelberg, 2003.

27

